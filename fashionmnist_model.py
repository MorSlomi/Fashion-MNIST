# -*- coding: utf-8 -*-
"""FashionMNIST_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XSgw5_5etT5XfMq4i0W0uVlC3ZOc1Og5
"""

# Importing libraries
import numpy as np
from matplotlib import pyplot
from sklearn.model_selection import KFold
from keras.datasets import fashion_mnist
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D,Dense,MaxPooling2D,Dropout,Flatten, Activation, BatchNormalization,LeakyReLU
import matplotlib.pyplot as plt

# Loading Dataset
def load_dataset(img_r,img_c):
	# load dataset
	(trainX, trainY), (testX, testY) = fashion_mnist.load_data()
	# reshape dataset to have a single channel
	trainX = trainX.reshape((trainX.shape[0], img_r,img_c, 1))
	testX = testX.reshape((testX.shape[0], img_r,img_c, 1))
	# one hot encode target values
	trainY = to_categorical(trainY)
	testY = to_categorical(testY)
  # convert from integers to floats
	trainX = trainX.astype('float32')
	testX = testX.astype('float32')
	return trainX, trainY, testX, testY

# Implementing the model
def build_model(trainX, trainY,batch_size,epochs, num_topics, drop_rate):
  model = Sequential()

  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1),padding='same'))
  model.add(BatchNormalization())
  model.add(Conv2D(32, (3, 3), activation='relu',padding='same'))
  model.add(BatchNormalization())
  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
  model.add(Dropout(drop_rate))

  model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='same'))
  model.add(BatchNormalization())
  model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))
  model.add(BatchNormalization())
  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
  model.add(Dropout(drop_rate))

  model.add(Conv2D(128, kernel_size=(3, 3),activation='relu',padding='same'))
  model.add(BatchNormalization())
  model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))
  model.add(BatchNormalization())
  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
  model.add(Dropout(drop_rate))

  model.add(Conv2D(256, kernel_size=(3, 3),activation='relu',padding='same'))
  model.add(BatchNormalization())
  model.add(Conv2D(256, (3, 3), activation='relu',padding='same'))
  model.add(BatchNormalization())
  model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
  model.add(Dropout(drop_rate))

  model.add(Flatten())
  model.add(Dense(500,use_bias=False,activation='relu'))
  model.add(BatchNormalization())
  model.add(Dropout(drop_rate)) 
  model.add(Dense(num_topics, activation='softmax'))
  
  # Compile the model
  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
  # Train the model
  history = model.fit(trainX, trainY, epochs=EPOCHS, batch_size=BS, validation_data=(testX, testY), shuffle=True)
  score = model.evaluate(testX, testY, verbose=0)
  return score ,history

def curves(fashion_train):
  accuracy = fashion_train.history['accuracy']
  val_accuracy = fashion_train.history['val_accuracy']
  loss = fashion_train.history['loss']
  val_loss = fashion_train.history['val_loss']
  epochs = range(len(accuracy))
  # Plots
  plt.plot(epochs, accuracy, 'mo', label='Training accuracy')
  plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
  plt.title('Training and validation accuracy')
  plt.legend()
  plt.savefig('/content/drive/My Drive/FashionAI/FashionMNISTCurvesAcc.jpg')

  plt.figure()
  plt.plot(epochs, loss, 'mo', label='Training loss')
  plt.plot(epochs, val_loss, 'b', label='Validation loss')
  plt.title('Training and validation loss')
  plt.legend()
  plt.savefig('/content/drive/My Drive/FashionAI/FashionMNISTCurvesLoss.jpg')

  plt.show()

BS = 256
EPOCHS = 20
NUM_TOPICS = 10
DROP_RATE = 0.5
IMG_R, IMG_C = 28, 28
CLASSES_LABELS = ['T-shirt/top', 'Trouser/pants', 'Pullover shirt', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# loading the dataset
trainX, trainY, testX, testY = load_dataset(IMG_R, IMG_C)
# evaluating the model
scores, histories = build_model(trainX, trainY, BS, EPOCHS, NUM_TOPICS, DROP_RATE)

# learning curves
curves(histories)

print('Accuracy:{} \nLoss:{}'.format(scores[1] ,scores[0]))